{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"float:left;\">Licence CC BY-NC-ND</span><span style=\"float:right;\">Thierry Parmentelat - Inria&nbsp;<img src=\"media/inria-25.png\" style=\"display:inline\"></span><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simplistic orchestration engine\n",
    "\n",
    "The main and single purpose of this library is to allow for the static description of a scenario involving `asyncio`-compliant jobs, that have dependencies in the sense that a given job cannot start until its requirements have not completed.\n",
    "\n",
    "So in a nutshell you would:\n",
    "\n",
    "* define a set of `Job` objects, \n",
    "* together with their `requires` relationship; that is to say, for each of them, which other jobs need to have completed before this one can be started,\n",
    "* and run this logic through an `Engine` object, that will orchestrate the whole secenario \n",
    "\n",
    "Further features allow to\n",
    "\n",
    "* define a job as running `forever`, in which case the engine of course won't wait for it, but instead will terminate it when all other jobs are done;\n",
    "* define a job as `critical`; a critical job that raises an exception causes the orchestration to terminate abruptly;\n",
    "* define a global `timeout` for the whole engine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A job object can be created:\n",
    "\n",
    "* either as a `Job` instance from a regular asyncio coroutine\n",
    "* or by specializing the `AbstractJob` class and defining its `co_run()` method\n",
    "\n",
    "As a convenience, the `Sequence` class is mostly a helper class that can free you from manually managing the `requires` deps in long strings of jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip3 install asynciojobs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a simple coroutine for the sake of illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "async def mycoro(timeout):\n",
    "    print(\"-> mycoro({})\".format(timeout))\n",
    "    await asyncio.sleep(timeout)\n",
    "    print(\"<- mycoro({})\".format(timeout))\n",
    "    # return something easy to recognize: the number of milliseconds\n",
    "    return 1000 * timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a series of coroutines in parallel - a la `gather` - can be done like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from asynciojobs import Job, Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a1, a2, a3 = Job(mycoro(0.1)), Job(mycoro(0.2)), Job(mycoro(0.25)),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're saying here is that we have three jobs, that have no relationships between them. \n",
    "\n",
    "So when we run them, we would start all 3 coroutines at once, and return once they are all done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ea = Engine(a1, a2, a3)\n",
    "ea.orchestrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = mycoro(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example B : add requirements (dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add *requirements* dependencies between jobs, like in the following example. We take this chance to show that jobs can be tagged with a label, which can turn out te be convenient somtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1, b2, b3 = (Job(mycoro(0.1), label=\"b1\"),\n",
    "              Job(mycoro(0.2), label=\"b2\"),\n",
    "              Job(mycoro(0.25)))\n",
    "\n",
    "b2.requires(b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `b3` needs `b1` to be finished before it can start. And so only the 2 first coroutines get started at the beginning, and only once b1 has finished does b3 start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with this setup we are certain that b3 ends in the middle of b2\n",
    "eb = Engine(b1, b2, b3)\n",
    "eb.orchestrate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exemple B' : exact same using a `Sequence`\n",
    "\n",
    "The code above in example B is exactly identical to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from asynciojobs import Sequence\n",
    "\n",
    "ebp = Engine(Sequence(Job(mycoro(0.1), label=\"bp1\"),\n",
    "                      Job(mycoro(0.2), label=\"bp2\")),\n",
    "             Job(mycoro(0.25)))\n",
    "\n",
    "ebp.orchestrate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect results\n",
    "\n",
    "Before we see more examples, let's see how details for each `Job` can be retrieved once `orchestrate` finishes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a shorter equivalent form would be \n",
    "# e2.list()\n",
    " \n",
    "for job in eb.jobs:\n",
    "    print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(b1.is_done())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(b3.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example C : infinite loops, or coroutines that don't return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is useful to deal with a endless loop; for example if we want to separate completely actions and printing, we can use an `asyncio.Queue` to implement a simple message bus as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "message_bus = asyncio.Queue()\n",
    "\n",
    "async def monitor_loop(bus):\n",
    "    while True:\n",
    "        message = await bus.get()\n",
    "        print(\"BUS: {}\".format(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a modified version of the previous coroutine, that interacts with this message bus instead of printing anything itself&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "async def mycoro_bus(timeout, bus):\n",
    "    await bus.put(\"-> mycoro({})\".format(timeout))\n",
    "    await asyncio.sleep(timeout)\n",
    "    await bus.put(\"<- mycoro({})\".format(timeout))\n",
    "    # return something easy to recognize\n",
    "    return 10 * timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replay the prevous scenario, adding the monitoring loop as a separate job; however we need to declare this job with `forever=True` so that we know when the bulk of the scenario is completed, since the monitoring loop will never return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1, c2, c3, c4 = (Job(mycoro_bus(0.2, message_bus), label=\"c1\"),\n",
    "                  Job(mycoro_bus(0.4, message_bus), label=\"c2\"), \n",
    "                  Job(mycoro_bus(0.3, message_bus), label=\"c3\"),\n",
    "                  Job(monitor_loop(message_bus), forever=True, label=\"monitor\"))\n",
    "\n",
    "c3.requires(c1)\n",
    "\n",
    "ec = Engine(c1, c2, c3, c4)\n",
    "ec.orchestrate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `orchestrate` always terminates as soon as all the non-`forever` jobs are complete. The `forever` jobs, on the other hand, get cancelled, so of course no return value is available at the end of the scenario&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ec.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example D : specifying a global timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`orchestrate` accepts a `timeout` argument in seconds. When provided, `orchestrate` will ensure its global duration does not exceed this value, and will return `False` if the timeout triggers.\n",
    "\n",
    "Of course this can be used with any number of jobs and dependencies, but for the sake of simplicity let us see this in action with just one job that loops forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "async def forever():\n",
    "    for i in range(100000):\n",
    "        print(\"{}: forever {}\".format(time.strftime(\"%H:%M:%S\"), i))\n",
    "        await asyncio.sleep(.1)\n",
    "        \n",
    "j = Job(forever(), forever=True)\n",
    "e = Engine(j)\n",
    "e.orchestrate(timeout=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the result of `orchestrate` in this case is `False`, since not all jobs have completed. Apart from that the jobs is now in this state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handling exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A job instance can be **critical** or not; what this means is as follows\n",
    "\n",
    " * if a critical job raises an exception, the whole engine aborts immediately and returns False\n",
    " * if a non-critical job raises an exception, the whole engine proceeds regardless\n",
    " \n",
    "In both cases the exception can be retrieved in the corresponding Job object with `raised_exception()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, the **critical** property can be set either at the `Job` or at the `Engine` level. Of course the former takes precedence if set. The default for an engine object is `critical=False`. Let us see this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example E : non critical jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "async def boom(n):\n",
    "    await asyncio.sleep(n)\n",
    "    raise Exception(\"boom after {}s\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# by default everything is non critical\n",
    "e1 = Job(mycoro(0.2))\n",
    "e2 = Job(boom(0.2), label=\"boom\")\n",
    "e3 = Job(mycoro(0.3))\n",
    "e2.requires(e1)\n",
    "e3.requires(e2)\n",
    "\n",
    "e = Engine(e1, e2, e3)\n",
    "print(\"orch:\", e.orchestrate())\n",
    "e.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example F : critical jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to make the boom job critical we can either set that on the job or on the engine object\n",
    "e1 = Job(mycoro(0.2))\n",
    "e2 = Job(boom(0.2), label=\"boom\", critical=True)\n",
    "e3 = Job(mycoro(0.3))\n",
    "e2.requires(e1)\n",
    "e3.requires(e2)\n",
    "\n",
    "e = Engine(e1, e2, e3)\n",
    "print(\"orchestrate:\", e.orchestrate())\n",
    "e.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `co_orchestrate` \n",
    "\n",
    "`orchestrate` is a regular `def` function (i.e. not an `async def`), but in fact just a wrapper around the native coroutine called `co_orchestrate`.\n",
    "\n",
    "    def orchestrate(self, loop=None, *args, **kwds):\n",
    "        if loop is None:\n",
    "            loop = asyncio.get_event_loop()\n",
    "        return loop.run_until_complete(self.co_orchestrate(loop=loop, *args, **kwds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `debrief()` and `list()`\n",
    "\n",
    "`Engine.list()` shows a complete list of the jobs, in a format designed for quickly grasping where you are.\n",
    "\n",
    "`Engine.debrief()` is designed for engines that have run and returned `False`, it does output the same listing as `list()` but with additional statistics on the number of jobs, and, most importantly, on the stacks of jobs that have raised an exception.\n",
    "\n",
    "\n",
    "* here's the legend of symbols used\n",
    "\n",
    "|          |   |\n",
    "|----------|---|\n",
    "| critical                       | `⚠` |\n",
    "|raised an exception             | `★` |\n",
    "| went through without exception | `☉` |\n",
    "| complete | `☓` |\n",
    "| running  | `↺` |\n",
    "| idle     | `⚐` |\n",
    "| forever  | `∞`|\n",
    "\n",
    "* and here's an example of output for `list()` . \n",
    "\n",
    "```\n",
    "01 ⚠ ★ ☓ ∞ <J `forever=True crit.=True status=done boom=True` => CRIT. EXC.:!!bool:True!!>\n",
    "02 ⚠ ★ ↺ ∞ <J `forever=True crit.=True status=ongoing boom=True` => CRIT. EXC.:!!bool:True!!> - requires:{01}\n",
    "03 ⚠ ★ ☓   <J `forever=False crit.=True status=done boom=True` => CRIT. EXC.:!!bool:True!!> - requires:{02}\n",
    "04 ⚠ ★ ↺   <J `forever=False crit.=True status=ongoing boom=True` => CRIT. EXC.:!!bool:True!!> - requires:{03}\n",
    "05 ⚠ ☉ ☓ ∞ <J `forever=True crit.=True status=done boom=False` -> 0> - requires:{04}\n",
    "06 ⚠ ☉ ↺ ∞ <J `forever=True crit.=True status=ongoing boom=False`> - requires:{05}\n",
    "07 ⚠   ⚐ ∞ <J `forever=True crit.=True status=idle boom=False`> - requires:{06}\n",
    "08 ⚠ ☉ ☓   <J `forever=False crit.=True status=done boom=False` -> 0> - requires:{07}\n",
    "09 ⚠ ☉ ↺   <J `forever=False crit.=True status=ongoing boom=False`> - requires:{08}\n",
    "10 ⚠   ⚐   <J `forever=False crit.=True status=idle boom=False`> - requires:{09}\n",
    "11   ★ ☓ ∞ <J `forever=True crit.=False status=done boom=True` => exception:!!bool:True!!> - requires:{10}\n",
    "12   ★ ↺ ∞ <J `forever=True crit.=False status=ongoing boom=True` => exception:!!bool:True!!> - requires:{11}\n",
    "13   ★ ☓   <J `forever=False crit.=False status=done boom=True` => exception:!!bool:True!!> - requires:{12}\n",
    "14   ★ ↺   <J `forever=False crit.=False status=ongoing boom=True` => exception:!!bool:True!!> - requires:{13}\n",
    "15   ☉ ☓ ∞ <J `forever=True crit.=False status=done boom=False` -> 0> - requires:{14}\n",
    "16   ☉ ↺ ∞ <J `forever=True crit.=False status=ongoing boom=False`> - requires:{15}\n",
    "17     ⚐ ∞ <J `forever=True crit.=False status=idle boom=False`> - requires:{16}\n",
    "18   ☉ ☓   <J `forever=False crit.=False status=done boom=False` -> 0> - requires:{17}\n",
    "19   ☉ ↺   <J `forever=False crit.=False status=ongoing boom=False`> - requires:{18}\n",
    "20     ⚐   <J `forever=False crit.=False status=idle boom=False`> - requires:{19}\n",
    "```\n",
    "\n",
    "Note that if your locale/terminal cannot output these, the code will tentatively resort to pure ASCII output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `rain_check`\n",
    "\n",
    "`rain_check` will check for cycles in the requirements graph. It returns a boolean. It's a good idea to call it before running an orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sanitize`\n",
    "\n",
    "In some cases like esp. test scenarios, it can be helpful to add requirements to jobs that are not in the engine. The `sanitize` method removes such extra requirements, and unless you are certain it is not your case, it might be a good idea to call it explcitly before an orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `co_shutdown`\n",
    "\n",
    "Before returning, `orchestrate` sends the `co_shutdown()` method on all jobs. The default behaviour - in the `Job` class - is to do nothing, but this can be redefined when relevant. Typically, an implementation of an `SshJob` will allow for a given SSH connection to be shared amongs several `SshJob` instances, and so `co_shutdown()` may be used to  close the underlying SSH connections at the end of the scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `export_as_dotfile`\n",
    "\n",
    "An engine can be exported as a dotfile for feeding `graphviz` and producing visual diagrams. Provided that you have the `dot` program (which is part of `graphviz`) installed, you could do something like\n",
    "\n",
    "    e.save_as_dotfile('foo.dot')\n",
    "    os.system(\"dot -Tpng foo.dot -o foo.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the `Sequence` class\n",
    "\n",
    "You can group jobs in sequences so you don't need to worry about requirements. This might still be a little brittle for now. You can nest sequences in sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from asynciojobs import Sequence\n",
    "\n",
    "e = Engine (Sequence(Job(mycoro(1), label=\"j1\"), \n",
    "                     Job(mycoro(2), label=\"lab2\"), \n",
    "                     Job(mycoro(3), label=\"tag3\")))\n",
    "e.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customizing the `Job` class\n",
    "\n",
    "`Job` actually is a specializtion of `AbstractJob`, and the specification is that the `co_run()` method should denote a coroutine itself, and that is what is triggered by `Engine` for running said job.\n",
    "\n",
    "You can define your own `Job` class by specializing `job.AbstractJob` - more on this later, we'll define some predefined jobs, in particular for interacting through ssh, and possibly many others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "### termination and re-run\n",
    "\n",
    "1. related: for the tests at least, and maybe also in practical life, if we create an engine that does not pass  `rain_check`, and so don't run orchestrate, then we'd need a means to garbage collect the pending coroutines\n",
    "\n",
    "1. also related: there is an intention in the code that one engine object can be run several times. Looks like this won't work as expected anymore, and it can be an issue in the context of reproducible research: we may/will want to run the same scenario object several times, don't we ? \n",
    "\n",
    " * This maybe is not too serious; we may get away with that by just doing\n",
    " \n",
    "instead of\n",
    "\n",
    "```\n",
    "e = Engine(Job(coro(1)), Job(coro(2))\n",
    "e.orchestrate()\n",
    "# won't work again because the coroutines have dried out\n",
    "e.orchestrate()\n",
    "```\n",
    "\n",
    "do this\n",
    "\n",
    "```\n",
    "def run():\n",
    "   e = Engine(Job(coro(1)), Job(coro(2))\n",
    "   e.orchestrate()\n",
    "\n",
    "# this of course works\n",
    "run()\n",
    "run()\n",
    "\n",
    "```\n",
    " \n",
    "\n",
    "### monitoring \n",
    "* come up with some basic (curses ?) monitor to show what's going on; what I have in mind is something like rhubarbe load where all jobs would be displayed, one line each, and their status could be shown so that one can get a sense of what is going on\n",
    "* one way to look at this is to have the main Engine class send itself a `tick()` method, and then specialize `Engine` as `EngineCurses` that would actually do things on such events.\n",
    "* ***or*** this gets delegated on a `message_queue` object. **Review the rhubarbe code on this aspect**.\n",
    "\n",
    "### convenience\n",
    "* ~~do we want to support requires by labels ?~~ : NO\n",
    "\n",
    "* **BUT** it would make sense to allow `requires` to be passed at job creation time ?\n",
    "\n",
    "```\n",
    "a1 = J(mycoro(1), label=\"a1\")\n",
    "a2 = J(mycoro(2), requires = [a1], label=\"a2\")\n",
    "a3 = J(mycoro(3), requires = [a1, a2])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical notes\n",
    "\n",
    "The purpose is to come up with an as-simple-as-it-gets replacement for our toolset for orchestrating network experiments. In its simplest form, it can be described as an ***orchestration tool for `asyncio`-based libraries***, with the following objectives\n",
    "\n",
    "* we ***primarily*** target ***ssh-based*** kind of interactions with nodes; typically we need to control any number of nodes reachable through ssh, ranging from hundreds of them in the context of PlanetLab, down to tens or a handful in the context of R2lab\n",
    "* previous tools like in particular [NEPI](http://nepi.inria.fr) came with a very ambitious goal of being extremely generic, to the cost of achieving poor to very poor performance, in particular in the specific niche of ssh-addressable nodes; in contrast, here we want to achieve optimal performance, to the possible cost of generality.\n",
    "\n",
    "So in order to take these objectives into account:\n",
    "\n",
    "* we want to have full control on ssh connections, and specifically to open only one such connection per node for the whole duration of the exp.\n",
    "* `asyncio` allows us to be totally single-threaded, so no multi-threading is needed, and thus no critical section nonsense\n",
    "* similarly we want to be able to rely on the internal ssh protocol to be notified when a remote command is done, ***instead of having to cyclically*** check for its status, which comes at an incredibly high cost\n",
    "\n",
    "It appears that the only critical feature required here as compared to what `asyncio` offers out of the box, is to handle dependencies between atomic jobs. It the main and only purpose of this micro-tool, to allow an experimenter to describe its experiment as a logically ordered set of jobs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I hope it will turn out, all this applies in a straightforward way to both\n",
    "\n",
    "* simple ssh-derivatives; at this point, it looks like we essentially need 2 first-class citizens here:\n",
    "  * running commands native to the remote system, or \n",
    "  * pushing a local script remotely and run it\n",
    "\n",
    "* but in fact the same applies as-is to any kind of coroutine, that could either\n",
    "  * have a local purpose, like dealing with a local software bus for exchanging messages between jobs\n",
    "  * or at the other extreme of the spectrum, interact with network resource using technologies totally different from `ssh`, provided that they rely on `asyncio`-aware libraries. Virtually everything is available as `asyncio`-compliant these days, from `http` to `telnet` - already used e.g. in `rhubarbe` - to, I am sure, `xmlrpc` or other more modern variants based on JSON, as well as XMPP-based stuff, if need be. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notebookname": "Installing",
  "version": "1.0"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
